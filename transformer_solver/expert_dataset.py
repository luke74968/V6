# transformer_solver/expert_dataset.py

import json
import torch
from torch.utils.data import Dataset
from tensordict import TensorDict
from tqdm import tqdm
from typing import Tuple, List

from .solver_env import PocatEnv
from .solver_env import BATTERY_NODE_IDX

# --- ğŸ‘‡ [ì‹ ê·œ] ì»¤ìŠ¤í…€ Collate í•¨ìˆ˜ ---
def expert_collate_fn(batch: List[Tuple[TensorDict, torch.Tensor]]) -> Tuple[TensorDict, torch.Tensor]:
    """
    Custom collate function to stack TensorDicts and Tensors from the ExpertReplayDataset.
    PyTorchì˜ default_collateëŠ” TensorDictë¥¼ ì²˜ë¦¬í•˜ì§€ ëª»í•˜ë¯€ë¡œ ì´ í•¨ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.
    """
    # batchëŠ” íŠœí”Œ ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤: [(td_batch_1, reward_batch_1), (td_batch_2, reward_batch_2), ...]
    
    # 1. íŠœí”Œ ë¦¬ìŠ¤íŠ¸ë¥¼ ë‘ ê°œì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤.
    td_list = [item[0] for item in batch]
    reward_list = [item[1] for item in batch]
    
    # 2. torch.stack()ì„ ì‚¬ìš©í•˜ì—¬ TensorDict ë¦¬ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ (B, ...) TensorDictë¡œ ë¬¶ìŠµë‹ˆë‹¤.
    batched_tds = torch.stack(td_list, dim=0)
    
    # 3. torch.cat()ì„ ì‚¬ìš©í•˜ì—¬ ë³´ìƒ ë¦¬ìŠ¤íŠ¸ë¥¼ (B, 1) í…ì„œë¡œ ë¬¶ìŠµë‹ˆë‹¤.
    # (ê° rewardëŠ” [1, 1] í˜•íƒœì´ë¯€ë¡œ cat(dim=0)ì„ ì‚¬ìš©)
    batched_rewards = torch.cat(reward_list, dim=0)
    
    return batched_tds, batched_rewards


class ExpertReplayDataset(Dataset):
    """
    'generate_expert_data.py'ë¡œ ìƒì„±ëœ "ì •ë‹µì§€" JSON íŒŒì¼ì„ ì½ì–´ì˜µë‹ˆë‹¤.
    JSON ì•ˆì˜ 'action_sequences'ë¥¼ í™˜ê²½ì—ì„œ í•œ ìŠ¤í…ì”© "ë¦¬í”Œë ˆì´(Replay)"í•˜ì—¬,
    ëª¨ë“  (ìƒíƒœ, ìµœì¢…_ë³´ìƒ) í˜ì–´(pair)ë¥¼ ë©”ëª¨ë¦¬ì— ë¡œë“œí•˜ëŠ” ì§€ë„í•™ìŠµìš© ë°ì´í„°ì…‹ì…ë‹ˆë‹¤.
    """
    def __init__(self, expert_data_path: str, env: PocatEnv, device: str = "cpu"):
        self.env = env
        self.generator = env.generator
        self.device = device
        self.replay_buffer = []

        print(f"\nğŸ§  'ì •ë‹µì§€' ë¦¬í”Œë ˆì´ ë°ì´í„°ì…‹ ìƒì„± ì¤‘...")
        print(f"   - ì •ë‹µì§€ íŒŒì¼ ë¡œë“œ: {expert_data_path}")
        
        try:
            with open(expert_data_path, 'r', encoding='utf-8') as f:
                expert_traces = json.load(f)
            if not isinstance(expert_traces, list):
                expert_traces = []
        except Exception as e:
            print(f"âŒ 'ì •ë‹µì§€' íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            expert_traces = []

        # tqdmìœ¼ë¡œ ë¦¬í”Œë ˆì´ ì§„í–‰ ìƒí™© í‘œì‹œ
        pbar = tqdm(expert_traces, desc="   - OR-Tools ê²½ë¡œ ë¦¬í”Œë ˆì´ ì¤‘")
        for trace in pbar:
            config_file = trace["config_file"]
            target_reward = trace["target_reward"]
            action_sequences = trace["action_sequences"] # [ [207, 181, 0], [208, 176, 0], ... ]
            
            # 1. ì •ë‹µì§€ì™€ ë™ì¼í•œ 'config'ë¡œ í™˜ê²½ í…ì„œ ìƒì„±
            # (PocatEnvëŠ” ì´ë¯¸ ì˜¬ë°”ë¥¸ configë¡œ ì´ˆê¸°í™”ë˜ì—ˆì§€ë§Œ, 
            #  V7(ì¼ë°˜í™”)ì„ ëŒ€ë¹„í•´ generatorë¥¼ ë‹¤ì‹œ í˜¸ì¶œí•˜ëŠ” ê²ƒì´ ë” ê²¬ê³ í•¨)
            try:
                # (ì£¼ì˜: ì´ ë¡œì§ì€ generatorê°€ config_file ê²½ë¡œë¥¼ ë°›ì•„ ë‹¤ì‹œ ì´ˆê¸°í™”í•  ìˆ˜ ìˆë‹¤ê³  ê°€ì •)
                # í˜„ì¬ V6 êµ¬ì¡°ì—ì„œëŠ” self.generatorë¥¼ ê·¸ëƒ¥ ì‚¬ìš©í•´ë„ ë©ë‹ˆë‹¤.
                # generator = PocatGenerator(config_file_path=config_file)
                generator = self.generator 
                
                # (B, 1) í¬ê¸°ì˜ ë³´ìƒ í…ì„œ ì¤€ë¹„
                target_reward_tensor = torch.tensor([[target_reward]], dtype=torch.float32, device=self.device)

                # 2. ëª¨ë“  ê²½ë¡œ(Load)ë¥¼ ìˆœíšŒ
                for path_actions in action_sequences:
                    # 3. í™˜ê²½ ë¦¬ì…‹
                    # (ë°°ì¹˜ í¬ê¸° 1ë¡œ ìƒˆ ë¬¸ì œì§€ ìƒì„±)
                    td_initial = generator(batch_size=1).to(self.device)
                    td = self.env._reset(td_initial)
                    
                    # 4. 'ì •ë‹µì§€'ì˜ Bottom-Up ê²½ë¡œë¥¼ í•œ ìŠ¤í…ì”© ë¦¬í”Œë ˆì´
                    # path_actions ì˜ˆì‹œ: [207, 181, 0]
                    for action_idx in path_actions:
                        
                        # (A) ë¦¬í”Œë ˆì´: í˜„ì¬ ìƒíƒœ(td)ì™€ ì •ë‹µ ë³´ìƒ(target_reward)ì„ ë²„í¼ì— ì €ì¥
                        # .clone()ìœ¼ë¡œ í…ì„œì˜ í˜„ì¬ ìŠ¤ëƒ…ìƒ·ì„ ì €ì¥
                        self.replay_buffer.append((td.clone(), target_reward_tensor.clone()))
                        
                        # (B) ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì´ë™
                        action_tensor = torch.tensor([[action_idx]], dtype=torch.long, device=self.device)
                        td.set("action", action_tensor)
                        td = self.env.step(td)["next"]
                        
                        if td["done"].item():
                            # (ê²½ë¡œ ì™„ì„± (head=0) ë˜ëŠ” ì‹¤íŒ¨ ì‹œ ë£¨í”„ ì¤‘ë‹¨)
                            break
                            
            except Exception as e:
                print(f"âŒ ë¦¬í”Œë ˆì´ ì¤‘ ì˜¤ë¥˜ ë°œìƒ (Trace: {config_file}): {e}")
                
        if not self.replay_buffer:
            print("âš ï¸ ê²½ê³ : 'ì •ë‹µì§€' ë¦¬í”Œë ˆì´ ê²°ê³¼, ìœ íš¨í•œ (ìƒíƒœ, ë³´ìƒ) ë°ì´í„°ê°€ 0ê°œì…ë‹ˆë‹¤.")
        else:
            print(f"âœ… 'ì •ë‹µì§€' ë¦¬í”Œë ˆì´ ì™„ë£Œ. ì´ {len(self.replay_buffer)}ê°œì˜ (ìƒíƒœ, ë³´ìƒ) í˜ì–´ ìƒì„±.")

    def __len__(self) -> int:
        return len(self.replay_buffer)

    def __getitem__(self, idx: int) -> Tuple[TensorDict, torch.Tensor]:
        # (state_td, target_reward) ë°˜í™˜
        # [BUG FIX] .squeeze(0)ë¥¼ ì œê±°í•´ì•¼ PyTorchì˜ default_collate í•¨ìˆ˜ê°€
        # (B=1, ...) í…ì„œë“¤ì„ (B=batch_size, ...)ë¡œ ì˜¬ë°”ë¥´ê²Œ stack/collate í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        # .squeeze(0)ë¥¼ í•˜ë©´ non-batch í…ì„œê°€ ë˜ì–´ collateê°€ __iter__ë¥¼ í˜¸ì¶œí•´ StopIterationì´ ë°œìƒí•©ë‹ˆë‹¤.
        return self.replay_buffer[idx] # (td [B=1], reward [B=1])