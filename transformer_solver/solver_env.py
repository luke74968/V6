# transformer_solver/pocat_env.py

import torch
from tensordict import TensorDict
from torchrl.envs import EnvBase
from typing import Optional, Dict, Union

from torchrl.data import Unbounded, UnboundedDiscrete, Composite

from .definitions import (
    SCALAR_PROMPT_FEATURE_DIM, FEATURE_DIM, FEATURE_INDEX,
    NODE_TYPE_BATTERY, NODE_TYPE_IC, NODE_TYPE_LOAD
)


# --- [í•µì‹¬] í•˜ì´ë¸Œë¦¬ë“œ ë³´ìƒ ê°€ì¤‘ì¹˜ ìƒìˆ˜ ---
# R_action: ì¦‰ê°ì ì¸ IC ë¹„ìš©ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ (0.0ìœ¼ë¡œ ì„¤ì • ì‹œ ìˆœìˆ˜ R_path)
REWARD_WEIGHT_ACTION = 0
# R_path: ê²½ë¡œ ì™„ì„± ì‹œ ëˆ„ì  ë¹„ìš©(staging_cost)ì— ëŒ€í•œ ê°€ì¤‘ì¹˜
REWARD_WEIGHT_PATH = 1.0
# ìŠ¤í… í˜ë„í‹°: ê²½ë¡œë¥¼ ë¶ˆí•„ìš”í•˜ê²Œ ê¸¸ê²Œ ë§Œë“œëŠ” ê²ƒì„ ë°©ì§€
STEP_PENALTY = 0
# R_fail: ì‹¤íŒ¨ ì‹œ í˜ë„í‹°
FAILURE_PENALTY = -100.0
# ğŸ‘ˆ [ì•”ì „ë¥˜] ì´ˆê³¼ëœ ì•”ì „ë¥˜ 1Aë‹¹ í˜ë„í‹° (ìŒìˆ˜ ë³´ìƒ) í¬ê¸°
PENALTY_WEIGHT_SLEEP = 1000.0 # ì˜ˆ: 1mA(0.001A) ì´ˆê³¼ ì‹œ -10.0ì˜ í˜ë„í‹°

BATTERY_NODE_IDX = 0

class PocatEnv(EnvBase):
    name = "pocat"

    def __init__(self, generator_params: dict = {}, device: str = "cpu", **kwargs):
        super().__init__(device=device)
        from .env_generator import PocatGenerator
        self.generator = PocatGenerator(**generator_params)
        
        # ë²„í¼ëŠ” _ensure_buffersì—ì„œ ë™ì ìœ¼ë¡œ ìƒì„±ë˜ë¯€ë¡œ __init__ì—ì„œëŠ” Noneìœ¼ë¡œ ì´ˆê¸°í™”
        self.register_buffer("arange_nodes", None, persistent=False)
        self.register_buffer("node_type_tensor", None, persistent=False)
        self.register_buffer("rail_types", None, persistent=False)

        self._make_spec()
        self._load_constraint_info()

    # --- [ê°œì„ ] ë²„í¼ í¬ê¸° ë™ê¸°í™” í•¨ìˆ˜ ì¶”ê°€ ---
    def _ensure_buffers(self, td: TensorDict):
        """ì—í”¼ì†Œë“œë§ˆë‹¤ ê·¸ë˜í”„/ë¡œë“œ ìˆ˜ê°€ ë°”ë€” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ ë²„í¼ë¥¼ ë™ê¸°í™”í•©ë‹ˆë‹¤."""
        num_nodes = td["nodes"].shape[1]

        if self.arange_nodes is None or self.arange_nodes.numel() != num_nodes:
            self.arange_nodes = torch.arange(num_nodes, device=self.device)
        
        # node_type_tensorëŠ” configì—ì„œ ì˜¤ë¯€ë¡œ ê³ ì •, __init__ì—ì„œ í•œ ë²ˆë§Œ ìƒì„±ë˜ë„ë¡ ìˆ˜ì •
        if (self.node_type_tensor is None) or (self.node_type_tensor.numel() != num_nodes):
            node_types_list = [self.generator.config.node_types[i] for i in range(num_nodes)]
            self.node_type_tensor = torch.tensor(node_types_list, dtype=torch.long, device=self.device)

        # rail_typesë„ configì—ì„œ ì˜¤ë¯€ë¡œ ê³ ì •
        if (self.rail_types is None) or (self.rail_types.numel() != self.generator.num_loads):
            rail_type_map = {"exclusive_supplier": 1, "exclusive_path": 2}
            load_configs = self.generator.config.loads
            rail_types_list = [rail_type_map.get(cfg.get("independent_rail_type"), 0) for cfg in load_configs]
            self.rail_types = torch.tensor(rail_types_list, dtype=torch.long, device=self.device) if rail_types_list else torch.tensor([], dtype=torch.long, device=self.device)

    def _make_spec(self):
        """í™˜ê²½ì˜ observation, action, reward ìŠ¤í™ì„ ì •ì˜í•©ë‹ˆë‹¤."""
        num_nodes = self.generator.num_nodes
        
        self.observation_spec = Composite({
            "nodes": Unbounded(shape=(num_nodes, FEATURE_DIM)),
            "scalar_prompt_features": Unbounded(shape=(SCALAR_PROMPT_FEATURE_DIM,)),
            "matrix_prompt_features": Unbounded(shape=(num_nodes, num_nodes)),
            "connectivity_matrix": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            "adj_matrix": Unbounded(shape=(num_nodes, num_nodes), dtype=torch.bool),
            "unconnected_loads_mask": Unbounded(shape=(num_nodes,), dtype=torch.bool),
            "trajectory_head": UnboundedDiscrete(shape=(1,)),
            "step_count": UnboundedDiscrete(shape=(1,)),
            # --- ğŸ‘‡ [ì—¬ê¸°ì— ìƒˆë¡œìš´ ìƒíƒœ ëª…ì„¸ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤] ---
            "current_cost": Unbounded(shape=(1,)),
            "staging_cost": Unbounded(shape=(1,)), # *í˜„ì¬ êµ¬ì¶• ì¤‘ì¸* ê²½ë¡œì˜ ëˆ„ì  ë¹„ìš©
            "is_used_ic_mask": Unbounded(shape=(num_nodes,), dtype=torch.bool),
            "current_target_load": UnboundedDiscrete(shape=(1,)),
            "is_exclusive_mask": Unbounded(shape=(num_nodes,), dtype=torch.long), # ğŸ‘ˆ [ì‹ ê·œ] 0: Normal, 1: Supplier, 2: Path
        })
        
        self.action_spec = UnboundedDiscrete(shape=(1,))
        self.reward_spec = Unbounded(shape=(1,))

    def _set_seed(self, seed: Optional[int] = None):
        if seed is not None:
            torch.manual_seed(seed)

    # ğŸ’¡ **[ë³€ê²½ 3]** ì œì•½ì¡°ê±´ ì •ë³´ë¥¼ ë¯¸ë¦¬ ê°€ê³µí•˜ì—¬ ì €ì¥í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
    def _load_constraint_info(self):
        """config íŒŒì¼ì—ì„œ ì œì•½ì¡°ê±´ ì •ë³´ë¥¼ ë¡œë“œí•˜ê³  ë§ˆìŠ¤í‚¹ì— ì‚¬ìš©í•˜ê¸° ì‰½ê²Œ ê°€ê³µí•©ë‹ˆë‹¤."""
        self.node_name_to_idx = {name: i for i, name in enumerate(self.generator.config.node_names)}
        
        # Independent Rail ì •ë³´
        self.exclusive_supplier_loads = set()
        self.exclusive_path_loads = set()

        loads_config = self.generator.config.loads
        if loads_config:
            load_start_idx = 1 + self.generator.num_ics
            for i, load_cfg in enumerate(loads_config):
                load_idx = load_start_idx + i
                if load_cfg.get("independent_rail_type") == "exclusive_supplier":
                    self.exclusive_supplier_loads.add(load_idx)
                elif load_cfg.get("independent_rail_type") == "exclusive_path":
                    self.exclusive_path_loads.add(load_idx)
            # setì— ì •ë³´ê°€ ì±„ì›Œì§„ í›„ tensorë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
            if self.exclusive_path_loads:
                self.exclusive_path_loads_tensor = torch.tensor(
                    sorted(self.exclusive_path_loads), dtype=torch.long, device=self.device
                )
        if self.exclusive_supplier_loads:
            self.exclusive_supplier_loads_tensor = torch.tensor(
                sorted(self.exclusive_supplier_loads), dtype=torch.long, device=self.device
            )
        else:
            self.exclusive_supplier_loads_tensor = torch.tensor([], dtype=torch.long, device=self.device)
        if not self.exclusive_path_loads:
            self.exclusive_path_loads_tensor = torch.tensor([], dtype=torch.long, device=self.device)

        # Power Sequence ì •ë³´ì— f í”Œë˜ê·¸(ë™ì‹œ í—ˆìš© ì—¬ë¶€) ì¶”ê°€
        self.power_sequences = []
        for seq in self.generator.config.constraints.get("power_sequences", []):
            f_flag = seq.get("f", 1)
            j_idx = self.node_name_to_idx.get(seq['j'])
            k_idx = self.node_name_to_idx.get(seq['k'])
            if j_idx is not None and k_idx is not None:
                self.power_sequences.append((j_idx, k_idx, f_flag))

    def select_start_nodes(self, td: TensorDict):
        node_types = td["nodes"][0, :, FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
        start_nodes_idx = torch.where(node_types == NODE_TYPE_LOAD)[0]
        return len(start_nodes_idx), start_nodes_idx
    
    def _trace_path_batch(self, start_nodes: torch.Tensor, adj_matrix: torch.Tensor) -> torch.Tensor:
        """ë°°ì¹˜ ì „ì²´ì— ëŒ€í•´ start_nodeë“¤ì˜ ëª¨ë“  ì¡°ìƒì„ ì°¾ì•„ ë§ˆìŠ¤í¬ë¡œ ë°˜í™˜í•©ë‹ˆë‹¤."""
        batch_size, num_nodes, _ = adj_matrix.shape
        path_mask = torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device)

        # start_nodesê°€ ë¹„ì–´ìˆì§€ ì•Šì„ ë•Œë§Œ scatter_ ì‹¤í–‰
        if start_nodes.numel() > 0:
            path_mask.scatter_(1, start_nodes.unsqueeze(-1), True)

        # í–‰ë ¬ ê³±ì…ˆì„ ì´ìš©í•´ ê·¸ë˜í”„ë¥¼ ê±°ìŠ¬ëŸ¬ ì˜¬ë¼ê°€ë©° ëª¨ë“  ì¡°ìƒì„ ì°¾ìŠµë‹ˆë‹¤.
        for _ in range(num_nodes):
            # í˜„ì¬ ê²½ë¡œì— í¬í•¨ëœ ë…¸ë“œë“¤ì˜ ë¶€ëª¨ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
            parents_mask = (
                # Use the transpose to follow incoming edges when accumulating parents.
                adj_matrix.transpose(-1, -2).float() @ path_mask.float().unsqueeze(-1)
            ).squeeze(-1).bool()            # ë” ì´ìƒ ìƒˆë¡œìš´ ë¶€ëª¨ê°€ ì—†ìœ¼ë©´ (ê²½ë¡œì˜ ëì— ë„ë‹¬í•˜ë©´) ì¢…ë£Œí•©ë‹ˆë‹¤.
            if (parents_mask & ~path_mask).sum() == 0: break
            # ìƒˆë¡œ ì°¾ì€ ë¶€ëª¨ë“¤ì„ ê²½ë¡œ ë§ˆìŠ¤í¬ì— ì¶”ê°€í•©ë‹ˆë‹¤.
            path_mask |= parents_mask
        return path_mask

    def _reset(self, td: Optional[TensorDict] = None, **kwargs) -> TensorDict:
        batch_size = kwargs.get("batch_size", self.batch_size)
        if td is None:
            batch_size = kwargs.get("batch_size", self.batch_size)
            if isinstance(batch_size, tuple): batch_size = batch_size[0]
            td_initial = self.generator(batch_size=batch_size).to(self.device)
        # tdê°€ ì¸ìë¡œ ë“¤ì–´ì˜¤ë©´, ê·¸ tdë¥¼ ì´ˆê¸° ìƒíƒœë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        else:
            td_initial = td
            # ë°°ì¹˜ í¬ê¸°ë„ ë“¤ì–´ì˜¨ tdì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.
            batch_size = td_initial.batch_size[0]

        num_nodes = td_initial["nodes"].shape[1]

        # --- ğŸ’¡ 1. Trajectory ê¸°ë°˜ ìƒíƒœ(state) ì¬ì •ì˜ ---
        reset_td = TensorDict({
            "nodes": td_initial["nodes"],
            "scalar_prompt_features": td_initial["scalar_prompt_features"],
            "matrix_prompt_features": td_initial["matrix_prompt_features"],
            "connectivity_matrix": td_initial["connectivity_matrix"],
            "adj_matrix": torch.zeros(batch_size, num_nodes, num_nodes, dtype=torch.bool, device=self.device),
            "trajectory_head": torch.full((batch_size, 1), BATTERY_NODE_IDX, dtype=torch.long, device=self.device),
            "unconnected_loads_mask": torch.ones(batch_size, num_nodes, dtype=torch.bool, device=self.device),
            "step_count": torch.zeros(batch_size, 1, dtype=torch.long, device=self.device),
            # --- ğŸ‘‡ [ì—¬ê¸°ì— ìƒˆë¡œìš´ ìƒíƒœ ì´ˆê¸°ê°’ì„ ì¶”ê°€í•©ë‹ˆë‹¤] ---
            "current_cost": torch.zeros(batch_size, 1, dtype=torch.float32, device=self.device),
            "staging_cost": torch.zeros(batch_size, 1, dtype=torch.float32, device=self.device), #
            "is_used_ic_mask": torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device),
            "current_target_load": torch.full((batch_size, 1), -1, dtype=torch.long, device=self.device),
            "is_exclusive_mask": torch.zeros(batch_size, num_nodes, dtype=torch.long, device=self.device), # ğŸ‘ˆ [ì‹ ê·œ] 0ìœ¼ë¡œ ì´ˆê¸°í™”
        }, batch_size=[batch_size], device=self.device)
       
        # ë°°í„°ë¦¬(ì¸ë±ìŠ¤ 0)ëŠ” í•­ìƒ ë©”ì¸ íŠ¸ë¦¬ì— í¬í•¨
        node_types = td_initial["nodes"][0, :, FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
        is_load = node_types == NODE_TYPE_LOAD
        reset_td["unconnected_loads_mask"][:, ~is_load] = False
        reset_td.set("done", torch.zeros(batch_size, 1, dtype=torch.bool, device=self.device))
        self._ensure_buffers(reset_td)
        return reset_td

    # ğŸ’¡ ì¶”ê°€ëœ step ë©”ì†Œë“œ: ë°°ì¹˜ í¬ê¸° ê²€ì‚¬ë¥¼ ìš°íšŒí•©ë‹ˆë‹¤.
    def step(self, tensordict: TensorDict) -> TensorDict:
        return self._step(tensordict)

    def _calculate_power_loss(self, ic_node_features: torch.Tensor, i_out: torch.Tensor) -> torch.Tensor:
        ic_type = ic_node_features[:, :, FEATURE_INDEX["ic_type_idx"]]
        vin = ic_node_features[:, :, FEATURE_INDEX["vin_min"]]
        vout = ic_node_features[:, :, FEATURE_INDEX["vout_min"]]

        power_loss = torch.zeros_like(i_out)
        
        # LDO
        ldo_mask = ic_type == 1.0
        if ldo_mask.any():
            op_current = ic_node_features[:, :, FEATURE_INDEX["op_current"]]
            power_loss[ldo_mask] = (vin[ldo_mask] - vout[ldo_mask]) * i_out[ldo_mask] + vin[ldo_mask] * op_current[ldo_mask]
        
        # Buck
        buck_mask = ic_type == 2.0
        if buck_mask.any():
            s, e = FEATURE_INDEX["efficiency_params"]
            a, b, c = ic_node_features[:, :, s:e].permute(2, 0, 1)
            i_out_buck = i_out[buck_mask]
            power_loss[buck_mask] = a[buck_mask] * (i_out_buck**2) + b[buck_mask] * i_out_buck + c[buck_mask]
            
        return power_loss

    def _step(self, td: TensorDict) -> TensorDict:
        batch_size, num_nodes, _ = td["nodes"].shape
        action = td["action"].reshape(batch_size)
        current_head = td["trajectory_head"].reshape(batch_size)

        # --- ğŸ‘‡ [í•µì‹¬ ë²„ê·¸ ìˆ˜ì • 1] ---
        # ì´ë¯¸ 'done' ìƒíƒœì¸ ìƒ˜í”Œì„ ì‹ë³„í•©ë‹ˆë‹¤. (B,)
        is_already_done = td["done"].squeeze(-1)
        
        # ë§Œì•½ ëª¨ë“  ìƒ˜í”Œì´ ì´ë¯¸ 'done'ì´ë©´, ì¦‰ì‹œ 0ì ì§œë¦¬ ë¦¬ì›Œë“œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
        if is_already_done.all():
            return TensorDict({
                "next": td, 
                "reward": torch.zeros(batch_size, device=self.device), 
                "done": td["done"]}, batch_size=td.batch_size)
        # --- ìˆ˜ì • ì™„ë£Œ ---

        # ğŸ’¡ [í•µì‹¬ ìˆ˜ì •] ì–•ì€ ë³µì‚¬ ëŒ€ì‹ , ìˆ˜ì •ë  í…ì„œë§Œ ê¹Šì€ ë³µì‚¬(deep copy)
        next_obs = td.clone() # ê»ë°ê¸°ëŠ” ì–•ì€ ë³µì‚¬
        next_obs["nodes"] = td["nodes"].clone()
        next_obs["adj_matrix"] = td["adj_matrix"].clone()
        next_obs["is_used_ic_mask"] = td["is_used_ic_mask"].clone()
        next_obs["current_target_load"] = td["current_target_load"].clone()
        # ---  staging_cost ë³µì œ ë° ìŠ¤í… ë¦¬ì›Œë“œ ì´ˆê¸°í™” ---
        next_obs["current_cost"] = td["current_cost"].clone()
        next_obs["staging_cost"] = td["staging_cost"].clone()
        # ê¸°ë³¸ ë³´ìƒ: ì‘ì€ ìŠ¤í… í˜ë„í‹° (ê²½ë¡œë¥¼ ì§§ê²Œ ë§Œë“¤ë„ë¡ ìœ ë„)
        step_reward = torch.full((batch_size,), STEP_PENALTY, dtype=torch.float32, device=self.device)
        # --- ìˆ˜ì • ì™„ë£Œ ---
        batch_indices = torch.arange(batch_size, device=self.device)

        # 1. ì•¡ì…˜ íƒ€ì…: [Select New Load]
        head_is_battery = current_head == BATTERY_NODE_IDX
        if head_is_battery.any():
            # [Select New Load]
            battery_rows = batch_indices[head_is_battery]
            action_from_battery = action[head_is_battery]

            # --- ğŸ‘‡ [í•µì‹¬ ë²„ê·¸ ìˆ˜ì •] ---
            # ì•¡ì…˜ì´ ì‹¤ì œ 'ë¡œë“œ'ì¸ ê²½ìš°ì™€ 'ë°°í„°ë¦¬(0)'(ì¢…ë£Œ)ì¸ ê²½ìš°ë¥¼ ë¶„ë¦¬
            is_load_selection = (action_from_battery != BATTERY_NODE_IDX)
            if is_load_selection.any():
                load_rows = battery_rows[is_load_selection]
                selected_load = action_from_battery[is_load_selection]

                next_obs["trajectory_head"][load_rows, 0] = selected_load
                next_obs["unconnected_loads_mask"][load_rows, selected_load] = False
                next_obs["current_target_load"][load_rows, 0] = selected_load
                next_obs["staging_cost"][load_rows] = 0.0
                
                # 'í‘œê¸°' ì‹œì‘: ë¡œë“œì˜ ë…ë¦½ ì¡°ê±´ì„ is_exclusive_maskì— ê¸°ë¡
                load_start_idx = 1 + self.generator.num_ics
                load_indices_in_config = selected_load - load_start_idx
                rail_types_to_set = self.rail_types[load_indices_in_config]
                next_obs["is_exclusive_mask"][load_rows, selected_load] = rail_types_to_set

            # (ì´ ìŠ¤í…ì˜ ë³´ìƒì€ STEP_PENALTYë§Œ ì ìš©ë¨)

            # (ì•¡ì…˜ì´ 0ë²ˆ(ë°°í„°ë¦¬)ì¸ ê²½ìš°ëŠ” ì•„ë¬´ ì‘ì—…ë„ í•˜ì§€ ì•Šê³  'Find Parent'ë¡œ ë„˜ì–´ê°)

        # 2. ì•¡ì…˜ íƒ€ì…: [Find Parent]
        head_is_node = ~head_is_battery
        if head_is_node.any():
            # [Find Parent]
            node_rows = batch_indices[head_is_node]
            child_node = current_head[head_is_node]
            parent_node = action[head_is_node]

            # 2. ì—°ê²° ì •ë³´ ë° ì‚¬ìš© ì—¬ë¶€ ì—…ë°ì´íŠ¸
            next_obs["adj_matrix"][node_rows, parent_node, child_node] = True
            node_types = td["nodes"][0, :, FEATURE_INDEX["node_type"][0]:FEATURE_INDEX["node_type"][1]].argmax(-1)
            # --- ğŸ‘‡ [í•µì‹¬ ìˆ˜ì • 3 & Point 1, 3 Fix] 'í‘œê¸°' ì „íŒŒ: ìì‹ì˜ ë…ë¦½ ì¡°ê±´ì„ ë¶€ëª¨ê°€ ë¬¼ë ¤ë°›ìŒ ---
            # (B_act,)
            child_status = next_obs["is_exclusive_mask"][node_rows, child_node]
            # 'child_status'ê°€ 0 (Normal)ì´ ì•„ë‹Œ ê²½ìš°ì—ë§Œ 'í‘œê¸°' ë¡œì§ ì‹¤í–‰
            if (child_status > 0).any():
                parent_status = next_obs["is_exclusive_mask"][node_rows, parent_node]

                # [Point 1, 5 Fix] dtypeì„ child_status.dtype (long)ìœ¼ë¡œ í†µì¼
                zero_tensor = torch.tensor(0, device=self.device, dtype=child_status.dtype)
                # 'Path(2)'ë§Œ ìƒìœ„ë¡œ ì „íŒŒë¨.
                status_to_propagate = torch.where(child_status == 2, child_status, zero_tensor)
                # ë¶€ëª¨ëŠ” (1)ìì‹ ì˜ ìƒíƒœ, (2)ì „íŒŒëœ Path, (3)ìì‹ì˜ Supplier(1) ìƒíƒœ ì¤‘ ê°€ì¥ ë†’ì€ ê°’ì„ ê°€ì§.
                status_from_child = torch.where(child_status == 1, child_status, status_to_propagate)
                new_parent_status = torch.max(parent_status, status_from_child)
                next_obs["is_exclusive_mask"][node_rows, parent_node] = new_parent_status
            # --- 'í‘œê¸°' ì „íŒŒ ì™„ë£Œ ---
            is_parent_ic = (node_types[parent_node] == NODE_TYPE_IC)
            if is_parent_ic.any():
                ic_rows = node_rows[is_parent_ic]
                ic_indices = parent_node[is_parent_ic]
                next_obs["is_used_ic_mask"][ic_rows, ic_indices] = True


            # 4. ë‹¤ìŒ í—¤ë“œ ê²°ì • (ë¹„ìš© ê³„ì‚° í›„ ìˆ˜í–‰)
            parent_is_battery = (parent_node == BATTERY_NODE_IDX)
            next_obs["trajectory_head"][node_rows, 0] = torch.where(parent_is_battery, BATTERY_NODE_IDX, parent_node)
            if parent_is_battery.any():
                finished_rows = node_rows[parent_is_battery]
                next_obs["current_target_load"][finished_rows, 0] = -1

        # 5. ì „ë¥˜, ì˜¨ë„, ë¹„ìš© ì—…ë°ì´íŠ¸
        # 1. ì´ˆê¸° ì „ë¥˜ ìˆ˜ìš”ëŠ” Loadì˜ active_currentë¡œ ì„¤ì •
        current_demands = next_obs["nodes"][..., FEATURE_INDEX["current_active"]].clone()
        ic_mask_b_n = (next_obs["nodes"][..., FEATURE_INDEX["node_type"][0] + NODE_TYPE_IC] == 1.0)
        current_demands[ic_mask_b_n] = 0.0 # (B, N) ë§ˆìŠ¤í¬ë¥¼ (B, N) í…ì„œì— ì§ì ‘ ì ìš©
        
        adj_matrix_T = next_obs["adj_matrix"].float().transpose(-1, -2)

        # 2. íŠ¸ë¦¬ ë ˆë²¨ ìˆ˜ë§Œí¼ ë°˜ë³µí•˜ì—¬ ì „ë¥˜ë¥¼ ìœ„ë¡œ ì „íŒŒ
        for _ in range(num_nodes):
            # ê° ë…¸ë“œì˜ ì¶œë ¥ ì „ë¥˜(I_out)ëŠ” ëª¨ë“  ìì‹ ë…¸ë“œë“¤ì˜ ìˆ˜ìš”(current_demands) í•©
            i_out = (adj_matrix_T @ current_demands.unsqueeze(-1)).squeeze(-1)
            
            # ê° ICì˜ ì…ë ¥ ì „ë¥˜(I_in) ê³„ì‚°
            op_current = next_obs["nodes"][..., FEATURE_INDEX["op_current"]]
            
            # LDO I_in = I_out + I_op
            i_in_ldo = i_out + op_current
            
            # Buckì˜ I_in = P_in / V_in + I_op = (P_out / eff) / V_in + I_op
            vout = next_obs["nodes"][..., FEATURE_INDEX["vout_min"]]
            vin = next_obs["nodes"][..., FEATURE_INDEX["vin_min"]]
            p_out_buck = vout * i_out
            # í™˜ê²½ ë‚´ì—ì„œëŠ” ë³µì¡í•œ íš¨ìœ¨ ê³¡ì„  ëŒ€ì‹  ë‹¨ìˆœí™”ëœ ê³ ì • íš¨ìœ¨(ì˜ˆ: 90%) ì‚¬ìš©
            eff = 0.9 
            # vinì´ 0ì¸ ê²½ìš°ë¥¼ ë°©ì§€
            safe_vin = torch.where(vin > 0, vin, 1e-6)
            i_in_buck = (p_out_buck / eff) / safe_vin + op_current
            # ë‹¤ìŒ ë°˜ë³µì„ ìœ„í•´ IC ë…¸ë“œì˜ ìˆ˜ìš”ë¥¼ ìƒˆë¡œ ê³„ì‚°ëœ I_in ê°’ìœ¼ë¡œ ì—…ë°ì´íŠ¸
            new_demands = current_demands.clone()
            ldo_mask_b = (next_obs["nodes"][..., FEATURE_INDEX["ic_type_idx"]] == 1.0)
            buck_mask_b = (next_obs["nodes"][..., FEATURE_INDEX["ic_type_idx"]] == 2.0)
            
            new_demands[ldo_mask_b] = i_in_ldo[ldo_mask_b]
            new_demands[buck_mask_b] = i_in_buck[buck_mask_b]
            
            # ë” ì´ìƒ ìˆ˜ìš”ê°€ ë³€í•˜ì§€ ì•Šìœ¼ë©´(ê³„ì‚° ì™„ë£Œ) ë£¨í”„ ì¢…ë£Œ
            if torch.allclose(current_demands, new_demands):
                break
            current_demands = new_demands
            
        # 3. ìµœì¢…ì ìœ¼ë¡œ ê³„ì‚°ëœ current_outì„ ì‚¬ìš©í•˜ì—¬ ì „ë ¥ ì†ì‹¤ ë° ì˜¨ë„ ê³„ì‚°
        final_i_out = (adj_matrix_T @ current_demands.unsqueeze(-1)).squeeze(-1)
        next_obs["nodes"][..., FEATURE_INDEX["current_out"]] = final_i_out
        power_loss = self._calculate_power_loss(next_obs["nodes"], final_i_out)
        theta_ja = next_obs["nodes"][..., FEATURE_INDEX["theta_ja"]]
        ambient_temp = self.generator.config.constraints.get("ambient_temperature", 25.0)
        new_temp = ambient_temp + power_loss * theta_ja
        next_obs["nodes"][..., FEATURE_INDEX["junction_temp"]] = new_temp
        
        node_costs = next_obs["nodes"][:, :, FEATURE_INDEX["cost"]]
        # ì´ë²ˆ ìŠ¤í…ìœ¼ë¡œ ì¸í•´ *ì „ì²´ ë¹„ìš©*ì´ ì¦ê°€í•œ ì–‘
        previous_total_cost = (td["is_used_ic_mask"].float() * node_costs).sum(dim=1, keepdim=True)
        new_total_cost = (next_obs["is_used_ic_mask"].float() * node_costs).sum(dim=1, keepdim=True)
        total_cost_increase = new_total_cost - previous_total_cost # (B, 1)

        # [Find Parent] ëª¨ë“œì˜€ë˜ ì¸ìŠ¤í„´ìŠ¤ì— ëŒ€í•´ì„œë§Œ R_action, R_path ì ìš©
        if head_is_node.any():
            # 3a. [ê³µí†µ] staging_costì— ë¹„ìš© ì¦ê°€ë¶„ì„ ëˆ„ì 
            next_obs["staging_cost"][node_rows] += total_cost_increase[node_rows]

            # 3b. R_action (ì•¡ì…˜ë³„ ë¹„ìš©) ë³´ìƒì„ ìŠ¤í… ë³´ìƒì— ì¶”ê°€
            #    (total_cost_increaseëŠ” (B,1) -> (B_act,)ë¡œ ë³€í™˜)
            step_reward[node_rows] += REWARD_WEIGHT_ACTION * (-total_cost_increase[node_rows].squeeze(-1))

            # 3c. R_path (ê²½ë¡œë³„ ë¹„ìš©) ë³´ìƒ
            finished_rows = node_rows[parent_is_battery]
            if finished_rows.numel() > 0:
                next_obs["trajectory_head"][finished_rows, 0] = BATTERY_NODE_IDX
                next_obs["current_target_load"][finished_rows, 0] = -1

                # ê²½ë¡œ ì™„ì„± ì‹œ, ëˆ„ì ëœ staging_costë¥¼ R_path ë³´ìƒìœ¼ë¡œ ì¶”ê°€
                sub_trajectory_total_cost = next_obs["staging_cost"][finished_rows]
                step_reward[finished_rows] += REWARD_WEIGHT_PATH * (-sub_trajectory_total_cost.squeeze(-1))

                # staging_costë¥¼ 0ìœ¼ë¡œ ë¦¬ì…‹í•˜ê³ , current_cost(ìµœì¢…ë¹„ìš©)ì— ë°˜ì˜
                next_obs["current_cost"][finished_rows] += sub_trajectory_total_cost
                next_obs["staging_cost"][finished_rows] = 0.0

            # 3d. ê²½ë¡œê°€ ì§„í–‰ ì¤‘ì¸ ì¸ìŠ¤í„´ìŠ¤
            in_progress_rows = node_rows[~parent_is_battery]
            if in_progress_rows.numel() > 0:
                next_obs["trajectory_head"][in_progress_rows, 0] = parent_node[~parent_is_battery]
                # (ë³´ìƒì€ ì´ë¯¸ STEP_PENALTY + R_action ìœ¼ë¡œ ì„¤ì •ë¨)
        # --- ìˆ˜ì • ì™„ë£Œ ---


        next_obs.set("step_count", td["step_count"] + 1)


        # 6. ì¢…ë£Œ ì¡°ê±´
        next_mask = self.get_action_mask(next_obs)
        is_stuck_or_finished = ~next_mask.any(dim=-1)
        all_loads_connected = (next_obs["unconnected_loads_mask"].sum(dim=1) == 0)
        trajectory_finished = (next_obs["trajectory_head"].squeeze(-1) == BATTERY_NODE_IDX)
        done_successfully = all_loads_connected & trajectory_finished
        max_steps = 2 * self.generator.num_nodes
        timed_out = (next_obs["step_count"] > max_steps).squeeze(-1)
        is_done = done_successfully | timed_out | is_stuck_or_finished
        next_obs["done"] = is_done.unsqueeze(-1)
        
        # --- ğŸ‘‡ [í•µì‹¬ ë²„ê·¸ ìˆ˜ì • 1] get_reward í˜¸ì¶œ ë° ìƒíƒœ ë®ì–´ì“°ê¸° ---
        final_reward = self.get_reward(
            next_obs,
            step_reward, # (B,) í…ì„œ (STEP_PENALTY + R_action + R_path)
            done_successfully,
            timed_out,
            is_stuck_or_finished
        )
        
        # ì´ë¯¸ 'done'ì´ì—ˆë˜ ìƒ˜í”Œë“¤ì€ ë³´ìƒì„ 0ìœ¼ë¡œ ê°•ì œí•˜ê³ , ìƒíƒœë¥¼ ë®ì–´ì“°ì§€ ì•ŠìŠµë‹ˆë‹¤.
        if is_already_done.any():
            final_reward[is_already_done] = 0.0
            next_obs[is_already_done] = td[is_already_done]
        # --- ìˆ˜ì • ì™„ë£Œ ---

        return TensorDict({
            "next": next_obs,
            "reward": final_reward.unsqueeze(-1),
            "done": next_obs["done"], # 'is_already_done' ìƒ˜í”Œë„ 'done=True'ë¡œ ìœ ì§€ë¨
        }, batch_size=batch_size)
        
# ğŸ’¡ *** ì—¬ê¸°ê°€ í•µì‹¬ ìˆ˜ì • ë¶€ë¶„ì…ë‹ˆë‹¤ (get_action_mask) ***
    def get_action_mask(self, td: TensorDict, debug: bool = False) -> Union[torch.Tensor, Dict[str, torch.Tensor]]:
        self._ensure_buffers(td) # ë§¨ ì•ì—ì„œ ë²„í¼ ë™ê¸°í™”
        
        batch_size, num_nodes, _ = td["nodes"].shape
        mask = torch.zeros(batch_size, num_nodes, dtype=torch.bool, device=self.device)
        current_head = td["trajectory_head"].squeeze(-1)
        
        reasons = {} # ë””ë²„ê·¸ ì´ìœ  ì €ì¥

        # --- 1. [Select New Load] ëª¨ë“œ ë§ˆìŠ¤í‚¹ ---
        head_is_battery = (current_head == BATTERY_NODE_IDX)
        if head_is_battery.any():
            all_has_unconnected = td["unconnected_loads_mask"].any(dim=-1)
            is_active = head_is_battery & all_has_unconnected
            is_finished = head_is_battery & ~all_has_unconnected
            
            mask[is_active] = td["unconnected_loads_mask"][is_active]
            mask[is_finished, BATTERY_NODE_IDX] = True
            
            if debug:
                reasons = {"Unconnected Load": td["unconnected_loads_mask"]}
            # (ì¤‘ìš”) head_is_batteryì™€ head_is_nodeëŠ” ìƒí˜¸ ë°°íƒ€ì ì´ë¯€ë¡œ,
            # [Find Parent] ë¡œì§ì´ ì‹¤í–‰ë  ìˆ˜ ìˆë„ë¡ ì—¬ê¸°ì„œ returní•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.


        # --- 2. [Find Parent] ëª¨ë“œ ë§ˆìŠ¤í‚¹ (ëª¨ë“  ì¡°ê±´ì„ í•œë²ˆì— ê³„ì‚°) ---
        head_is_node = ~head_is_battery
        if head_is_node.any():
            b_idx_node = torch.where(head_is_node)[0]
            child_nodes = current_head[head_is_node]
            node_types_tensor = self.node_type_tensor # (N,)
            B_act = len(b_idx_node) # (B_act,)
            
            # --- [ê³µí†µ ë§ˆìŠ¤í¬] ---
            # (1, N_nodes) -> (B_act, N_nodes)
            is_battery_mask = (self.arange_nodes.unsqueeze(0) == BATTERY_NODE_IDX).expand(B_act, -1)
            # (1, N_nodes) -> (B_act, N_nodes)
            not_load_parent = (self.node_type_tensor.unsqueeze(0) != NODE_TYPE_LOAD).expand(B_act, -1)
            # (B_act, 1) -> (B_act, N_nodes)
            not_self_parent = (self.arange_nodes.unsqueeze(0) != child_nodes.unsqueeze(1))

            
            # --- 1. ì „ì•• í˜¸í™˜ì„± ---
            # (B, N, N) -> (B_act, N, N)
            connectivity = td["connectivity_matrix"][b_idx_node] 
            # (B_act, 1, 1) -> (B_act, N, 1)
            child_indices_exp = child_nodes.view(-1, 1, 1).expand(-1, num_nodes, 1)
            # (B_act, N)
            volt_ok = torch.gather(connectivity, 2, child_indices_exp).squeeze(-1)

            # --- 2. ì‚¬ì´í´ ë°©ì§€ ---
            # (B_act, N)
            path_mask = self._trace_path_batch(child_nodes, td["adj_matrix"][b_idx_node])
            cycle_ok = ~path_mask

            # --- 3. ì „ë¥˜ í•œê³„ ---
            nodes_slice = td["nodes"][b_idx_node] # (B_act, N, D)
            rows = torch.arange(B_act, device=self.device) # (B_act,)
            # (B_act, N)
            remaining_capacity = nodes_slice[:, :, FEATURE_INDEX["i_limit"]] - nodes_slice[:, :, FEATURE_INDEX["current_out"]]
            # (B_act,) -> (B_act, 1)
            child_current_draw = nodes_slice[rows, child_nodes, FEATURE_INDEX["current_active"]].unsqueeze(1)
            # (B_act, N)
            current_ok = (remaining_capacity >= child_current_draw) | is_battery_mask

            
            # --- 4. [ë²„ê·¸ ìˆ˜ì •] ë…ë¦½(Exclusive) ì¡°ê±´ ---
            # (a) í˜„ì¬ Head(child_nodes)ì˜ ìƒíƒœ ì‹ë³„
            # (B_act,)
            head_status = td["is_exclusive_mask"][b_idx_node, child_nodes]
            
            # [Point 2 Fix] Headê°€ ë¡œë“œì¸ì§€ ICì¸ì§€ êµ¬ë³„
            # (B_act,)
            head_is_load = (node_types_tensor[child_nodes] == NODE_TYPE_LOAD)
            # (b) í›„ë³´ ë¶€ëª¨(Parent)ì˜ ìƒíƒœ ë° ìì‹ ìœ ë¬´ ìŠ¤ìº”
            # (B_act, N_nodes)
            parent_status = td["is_exclusive_mask"][b_idx_node]
            parent_is_exclusive = (parent_status > 0)
            
            load_start_idx = 1 + self.generator.num_ics
            load_end_idx = load_start_idx + self.generator.num_loads
            # (B_act, N_nodes) - ì´ ë¶€ëª¨ê°€ 'IC' ìì‹ì„ ê°€ì¡ŒëŠ”ê°€?
            has_ic_child = td["adj_matrix"][b_idx_node, :, 1:load_start_idx].any(dim=-1)
            # (B_act, N_nodes) - ì´ ë¶€ëª¨ê°€ 'Load' ìì‹ì„ ê°€ì¡ŒëŠ”ê°€?
            has_load_child = td["adj_matrix"][b_idx_node, :, load_start_idx:load_end_idx].any(dim=-1)
            # (B_act, N_nodes) - ë¶€ëª¨ê°€ *ì–´ë–¤* ìì‹ì´ë¼ë„ ê°€ì¡ŒëŠ”ê°€? (ì—£ì§€ì˜ í•© > 0)
            parent_has_any_child = has_ic_child | has_load_child
            
            # (c) ë‹˜ì˜ ê·œì¹™ ì •ì˜ (True = ìœ„ë°˜)
            # ê·œì¹™ 1: Headê°€ 'Path' (ë¡œë“œë“  ICë“ ) -> ë¶€ëª¨ëŠ” ìì‹ì´ ì—†ì–´ì•¼ í•¨.
            violation_Rule1 = (head_status.unsqueeze(-1) == 2) & parent_has_any_child
            # ê·œì¹™ 2: Headê°€ 'Supplier Load' -> ë¶€ëª¨ëŠ” ìì‹ì´ ì—†ì–´ì•¼ í•¨.
            violation_Rule2 = ((head_status == 1) & head_is_load).unsqueeze(-1) & parent_has_any_child
            # ê·œì¹™ 3: Headê°€ 'Normal' (Load/IC) ë˜ëŠ” 'Supplier IC' -> ë¶€ëª¨ëŠ” Exclusiveì´ë©´ ì•ˆ ë¨.
            violation_Rule3 = ((head_status == 0) | ((head_status == 1) & ~head_is_load)).unsqueeze(-1) & parent_is_exclusive
            # (d) ìœ„ë°˜ ì‚¬í•­ë“¤ì„ ì¢…í•© (True = ê¸ˆì§€)
            violations = violation_Rule1 | violation_Rule2 | violation_Rule3
            
            # (e) ê·œì¹™ 4 (Battery)ëŠ” í•­ìƒ í—ˆìš©
            exclusive_ok = torch.logical_not(violations) | is_battery_mask
            # --- [ë²„ê·¸ ìˆ˜ì • ì™„ë£Œ] ---
            # --- 5. ìµœì¢… ê²°í•© ---
            can_be_parent = (
                not_load_parent & not_self_parent & volt_ok & cycle_ok & 
                current_ok & exclusive_ok 
            )

            # --- 6. Power Sequence (ë£¨í”„ í•„ìš”) ---
            for j_idx, k_idx, f_flag in self.power_sequences:
                # Case 1: í˜„ì¬ childê°€ 'k'ì¼ ë•Œ (kì˜ ë¶€ëª¨ë¥¼ ì°¾ëŠ” ì¤‘)
                is_k_mask = (child_nodes == k_idx)
                if is_k_mask.any():
                    instances_to_check = torch.where(is_k_mask)[0]
                    b_idx_check = b_idx_node[instances_to_check]
                    adj_j = td["adj_matrix"][b_idx_check, :, j_idx]
                    parent_exists = adj_j.any(dim=-1)

                    if parent_exists.any():
                        b_constr = b_idx_check[parent_exists]
                        inst_constr = instances_to_check[parent_exists]
                        parent_of_j_idx = adj_j[parent_exists].long().argmax(-1)
                        
                        anc_mask = self._trace_path_batch(parent_of_j_idx, td["adj_matrix"][b_constr])
                        anc_mask[:, BATTERY_NODE_IDX] = False # ì¡°ìƒ ë§ˆìŠ¤í¬ì—ì„œ ë°°í„°ë¦¬ ì œì™¸
                        can_be_parent[inst_constr] &= ~anc_mask
                        
                        if f_flag == 1:
                            same_parent_mask = (self.arange_nodes == parent_of_j_idx.unsqueeze(1))
                            can_be_parent[inst_constr] &= ~same_parent_mask

                # Case 2: í˜„ì¬ childê°€ 'j'ì¼ ë•Œ (jì˜ ë¶€ëª¨ë¥¼ ì°¾ëŠ” ì¤‘)
                is_j_mask = (child_nodes == j_idx)
                if is_j_mask.any():
                    instances_to_check = torch.where(is_j_mask)[0]
                    b_idx_check = b_idx_node[instances_to_check]
                    adj_k = td["adj_matrix"][b_idx_check, :, k_idx]
                    parent_exists = adj_k.any(dim=-1)

                    if parent_exists.any():
                        b_constr = b_idx_check[parent_exists]
                        inst_constr = instances_to_check[parent_exists]
                        parent_of_k_idx = adj_k[parent_exists].long().argmax(-1)
                        
                        anc_mask = self._trace_path_batch(parent_of_k_idx, td["adj_matrix"][b_constr])
                        anc_mask[:, BATTERY_NODE_IDX] = False # ì¡°ìƒ ë§ˆìŠ¤í¬ì—ì„œ ë°°í„°ë¦¬ ì œì™¸
                        can_be_parent[inst_constr] &= ~anc_mask
                        
                        if f_flag == 1:
                            same_parent_mask = (self.arange_nodes == parent_of_k_idx.unsqueeze(1))
                            can_be_parent[inst_constr] &= ~same_parent_mask

            # ìµœì¢… ë§ˆìŠ¤í¬ë¥¼ ì „ì²´ ë°°ì¹˜ ë§ˆìŠ¤í¬ì— ì ìš©
            mask[head_is_node] = can_be_parent

            if debug:
                # [Find Parent] ëª¨ë“œ ì´ìœ ë¥¼ ë®ì–´ì“°ê¸°
                reasons.update({ 
                     "Not Load": not_load_parent,
                     "Not Self": not_self_parent,
                     "Volt OK": volt_ok,
                     "Cycle OK": cycle_ok,
                     "Current OK": current_ok,
                     "Exclusive OK": exclusive_ok, # ìˆ˜ì •ëœ ìµœì¢… ë¡œì§
                     "Sequence OK": can_be_parent # Power Sequenceê¹Œì§€ ì ìš©ëœ ìµœì¢…ë³¸
                 })

        # --- 3. ìµœì¢… ë°˜í™˜ ---
        if debug:
            return {"mask": mask, "reasons": reasons}
            
        return mask # ë””ë²„ê·¸ ëª¨ë“œê°€ ì•„ë‹ ë•Œ
    # ğŸ‘ˆ [ì•”ì „ë¥˜] í—¬í¼ í•¨ìˆ˜ (OR-Tools ë¡œì§ ê¸°ë°˜)
    def _calculate_total_sleep_current(self, td: TensorDict) -> torch.Tensor:
        """
        ì„±ê³µí•œ ìƒ˜í”Œë“¤(td)ì˜ ìµœì¢… ì•”ì „ë¥˜ í•©ê³„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        batch_size, num_nodes, _ = td["nodes"].shape
        adj_matrix = td["adj_matrix"].float()
        adj_matrix_T = adj_matrix.transpose(-1, -2) # (c, p)

        # 1. "Always-On" ìƒíƒœë¥¼ ë°°í„°ë¦¬ê¹Œì§€ ì „íŒŒ (B, N)
        always_on_loads = (td["nodes"][..., FEATURE_INDEX["always_on_in_sleep"]] == 1.0)
        always_on_nodes = always_on_loads.clone()
        always_on_nodes[:, BATTERY_NODE_IDX] = True # ë°°í„°ë¦¬ëŠ” í•­ìƒ AO
        
        for _ in range(num_nodes):
            # (B,N,N) @ (B,N,1) -> (B,N,1) -> (B,N)
            parents_mask = (adj_matrix_T @ always_on_nodes.float().unsqueeze(-1)).squeeze(-1).bool()
            if (parents_mask & ~always_on_nodes).sum() == 0: break
            always_on_nodes |= parents_mask
        
        # 2. IC ìì²´ ì•”ì „ë¥˜ ì†Œëª¨ ê³„ì‚° (B, N)
        is_ao = always_on_nodes
        is_used = td["is_used_ic_mask"]
        # (B,N,N) @ (B,N,1) -> (B,N) : ë‚´ ë¶€ëª¨(p)ê°€ AO(is_ao)ì¸ê°€?
        parent_is_ao = (adj_matrix_T @ is_ao.float().unsqueeze(-1)).squeeze(-1).bool()

        op_current = td["nodes"][..., FEATURE_INDEX["op_current"]]
        quiescent_current = td["nodes"][..., FEATURE_INDEX["quiescent_current"]]
        shutdown_current = td["nodes"][..., FEATURE_INDEX["shutdown_current"]]
        
        # shutdown_currentê°€ 0(ë¯¸ì •ì˜)ì´ë©´ quiescent_current ì‚¬ìš©
        use_ishut_current = torch.where(shutdown_current > 1e-9, shutdown_current, quiescent_current)

        ic_self_sleep = torch.zeros(batch_size, num_nodes, device=self.device)
        
        # ê·œì¹™ 1: ICê°€ AO ê²½ë¡œìƒì— ìˆìŒ -> Iop ì†Œëª¨
        ic_self_sleep[is_ao & is_used] = op_current[is_ao & is_used]
        # ê·œì¹™ 2: ICê°€ AOê°€ ì•„ë‹ˆì§€ë§Œ, ë¶€ëª¨ê°€ AO -> I_shut/Iq ì†Œëª¨
        ic_self_sleep[~is_ao & is_used & parent_is_ao] = use_ishut_current[~is_ao & is_used & parent_is_ao]
        # ê·œì¹™ 3: ê·¸ ì™¸ (ë¶€ëª¨ë„ AO ì•„ë‹˜) -> 0 ì†Œëª¨

        # 3. ë¡œë“œ ì•”ì „ë¥˜ ì†Œëª¨ ê³„ì‚° (B, N)
        # ì›ë³¸ td["nodes"]ê°€ ì˜¤ì—¼ë˜ì§€ ì•Šë„ë¡ .clone() ì‚¬ìš©
        load_sleep_draw_base = td["nodes"][..., FEATURE_INDEX["current_sleep"]].clone()
        load_sleep_draw = load_sleep_draw_base * always_on_nodes.float()
        # AO ê²½ë¡œê°€ ì•„ë‹Œ ë¡œë“œëŠ” ì „ë¥˜ 0
        load_sleep_draw[~always_on_nodes] = 0.0

        # 4. ì „ë¥˜ ìˆ˜ìš” ì „íŒŒ (LDO ë°©ì‹: I_in = I_out + I_self)
        current_demands_sleep = load_sleep_draw + ic_self_sleep
        ic_mask = (td["nodes"][..., FEATURE_INDEX["node_type"][0] + NODE_TYPE_IC] == 1.0)
        
        for _ in range(num_nodes):
            # I_out = sum(children's I_in)
            i_out_sleep = (adj_matrix_T @ current_demands_sleep.unsqueeze(-1)).squeeze(-1)
            
            # I_in = I_self + I_out (for ICs)
            new_demands_sleep = load_sleep_draw + ic_self_sleep
            new_demands_sleep[ic_mask] += i_out_sleep[ic_mask] # ICì˜ ìˆ˜ìš”ì— I_outì„ ë”í•¨
            
            if torch.allclose(current_demands_sleep, new_demands_sleep):
                break
            current_demands_sleep = new_demands_sleep

        # 5. ë°°í„°ë¦¬ì—ì„œ ë‚˜ê°€ëŠ” ì´ ì•”ì „ë¥˜ ê³„ì‚°
        battery_children_mask = adj_matrix[:, BATTERY_NODE_IDX, :] # (B, N)
        total_sleep_current = (current_demands_sleep * battery_children_mask).sum(dim=1)
        
        return total_sleep_current # (B,)


    
    # --- ğŸ‘‡ [í•µì‹¬ 5] get_reward í•¨ìˆ˜ ì‹œê·¸ë‹ˆì²˜ ë³€ê²½ ---
    def get_reward(self,
                   td: TensorDict,
                   step_reward: torch.Tensor, # _stepì—ì„œ ê³„ì‚°ëœ ê¸°ë³¸ ë³´ìƒ
                   done_successfully: torch.Tensor,
                   timed_out: torch.Tensor,
                   is_stuck_or_finished: torch.Tensor) -> torch.Tensor:
        

        """
        ë³´ìƒì„ ê³„ì‚°í•©ë‹ˆë‹¤.
        - ê¸°ë³¸ ë³´ìƒ: _stepì—ì„œ ê³„ì‚°ëœ ê°’ (ìŠ¤í… í˜ë„í‹° + R_action + R_path)
        - ìµœì¢… ë³´ìƒ: *ì‹¤íŒ¨* í˜ë„í‹° (ê²½ë¡œ ì‹¤íŒ¨, ì•”ì „ë¥˜ ìœ„ë°˜)
        """

        reward = step_reward.clone()

        # --- ğŸ‘‡ [ì•”ì „ë¥˜] ì•”ì „ë¥˜ ì œì•½ ê²€ì‚¬ ---
        if done_successfully.any():
            td_success = td[done_successfully]
            total_sleep_current = self._calculate_total_sleep_current(td_success)
            
            # scalar_prompt index 1 is max_sleep_current
            max_sleep_current = td_success["scalar_prompt_features"][:, 1]
            
            # --- ğŸ‘‡ [íŒì§€ í˜ë„í‹° ìˆ˜ì •] ---
            # (B_success,)
            violation_amount = total_sleep_current - max_sleep_current
            # Hinge Loss: max(0, violation_amount)
            hinge_violation = torch.relu(violation_amount) # 0 ë¯¸ë§Œ(ìœ„ë°˜ ì•ˆ í•¨)ì€ 0ìœ¼ë¡œ ì²˜ë¦¬

            # ì¦ë¶„í˜•(Incremental) í˜ë„í‹° ê³„ì‚° (ì–‘ìˆ˜ ê°’)
            sleep_penalty = PENALTY_WEIGHT_SLEEP * hinge_violation
            
            # [Point 2 Fix] reward[done_successfully]ì— ì§ì ‘ í˜ë„í‹° ì°¨ê° (ìŒìˆ˜ ë³´ìƒì— ë”í•¨)
            reward[done_successfully] -= sleep_penalty
            # --- [íŒì§€ í˜ë„í‹°] ìˆ˜ì • ì™„ë£Œ ---

        # --- [ì•”ì „ë¥˜] ê²€ì‚¬ ì™„ë£Œ ---
        # R_fail (ì‹¤íŒ¨ í˜ë„í‹°)
        # ì‹¤íŒ¨ ì‹œ, ì´ì „ê¹Œì§€ì˜ ë³´ìƒì„ ëª¨ë‘ ë®ì–´ì“°ê³  ê°•ë ¥í•œ í˜ë„í‹°ë¥¼ ë¶€ì—¬

        failed = (timed_out | is_stuck_or_finished) & ~done_successfully
        if failed.any():
            reward[failed] = FAILURE_PENALTY            
        return reward # (B,) í…ì„œ. í˜¸ì¶œë¶€(_step)ì—ì„œ (B, 1)ë¡œ unsqueezeí•¨.