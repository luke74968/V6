# V6/generate_expert_data.py
# (V6/transformer_solver/ ë° V6/or_tools_solver/ ì™€ ë™ì¼í•œ ìœ„ì¹˜ì— ì €ì¥)

import json
import sys
import os
import argparse
from dataclasses import asdict
from collections import defaultdict
from ortools.sat.python import cp_model
import torch # PocatGeneratorê°€ torch.deviceë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ ì„í¬íŠ¸ í•„ìš”

# --- 1. OR-Tools Solver ëª¨ë“ˆ ì„í¬íŠ¸ ---
from or_tools_solver.config_loader import load_configuration_from_file
from or_tools_solver.core import expand_ic_instances, create_solver_model
from common.ic_preprocessor import prune_dominated_ic_instances
# --- ğŸ‘‡ [ì‹ ê·œ] ì‹œê°í™” í•¨ìˆ˜ ì„í¬íŠ¸ ---
from or_tools_solver.solution_visualizer import print_and_visualize_one_solution

# --- 2. Transformer Solver ëª¨ë“ˆ ì„í¬íŠ¸ (ë§¤í•‘ ë° í›„ì²˜ë¦¬ìš©) ---
from transformer_solver.env_generator import PocatGenerator
from transformer_solver.solver_env import REWARD_WEIGHT_PATH, BATTERY_NODE_IDX
from transformer_solver.definitions import FEATURE_INDEX, NODE_TYPE_LOAD


def generate_expert_solution(config_filename, output_filename, max_sleep_override=None):
    """
    OR-Toolsë¥¼ ì‹¤í–‰í•˜ì—¬ ìµœì í•´ë¥¼ ì°¾ê³ , 
    Transformerê°€ í•™ìŠµí•  ìˆ˜ ìˆëŠ” 'ì •ë‹µì§€' (Bottom-Up ì•¡ì…˜ ì‹œí€€ìŠ¤ + ìµœì¢… ë³´ìƒ)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    (ìµœì í•´ì˜ ì‹œê°í™” .png íŒŒì¼ë„ í•¨ê»˜ ìƒì„±í•©ë‹ˆë‹¤)
    """
    print(f"ğŸ“– ì„¤ì • íŒŒì¼ '{config_filename}' ë¡œë”©...")
    
    # 1. ì„¤ì • ë¡œë“œ (OR-Tools ê¸°ì¤€)
    try:
        battery, available_ics, loads, constraints = load_configuration_from_file(config_filename)
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: ì„¤ì • íŒŒì¼ '{config_filename}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", file=sys.stderr)
        return
        
    if max_sleep_override is not None:
        constraints['max_sleep_current'] = max_sleep_override
        print(f"   - ì•”ì „ë¥˜ ì œì•½ ì˜¤ë²„ë¼ì´ë“œ: {max_sleep_override} A")

    # 2. ì „ì²˜ë¦¬ (or_tools_solver/main.pyì™€ ë™ì¼)
    candidate_ics, ic_groups = expand_ic_instances(available_ics, loads, battery, constraints)
    
    print("\nğŸ”ª Dominance Pruning ì „ì²˜ë¦¬ ì‹œì‘...")
    candidate_ics_dicts = [asdict(ic) for ic in candidate_ics]
    pruned_ics_dicts, _ = prune_dominated_ic_instances(candidate_ics_dicts)
    
    candidate_ics_map = {ic.name: ic for ic in candidate_ics}
    pruned_candidate_names = {ic_dict['name'] for ic_dict in pruned_ics_dicts}
    candidate_ics = [ic for name, ic in candidate_ics_map.items() if name in pruned_candidate_names]
    
    original_count = len(candidate_ics_dicts)
    pruned_count = len(candidate_ics)
    print(f"   - {original_count - pruned_count}ê°œ IC ì¸ìŠ¤í„´ìŠ¤ ì œê±° ì™„ë£Œ. (ë‚¨ì€ í›„ë³´: {pruned_count}ê°œ)")

    sanitized_ic_groups = {}
    # --- ğŸ‘‡ [ë²„ê·¸ ìˆ˜ì •] .values() -> .items() ---
    for group_key, group_list in ic_groups.items():
        sanitized_group_list = [name for name in group_list if name in pruned_candidate_names]
        if len(sanitized_group_list) > 1:
            sanitized_ic_groups[group_key] = sanitized_group_list

    # 3. OR-Tools ëª¨ë¸ ìƒì„± ë° ìµœì í•´ íƒìƒ‰
    print("\nğŸ§  OR-Tools ëª¨ë¸ ìƒì„± ë° ìµœì í•´ íƒìƒ‰ ì‹œì‘...")
    model, edges, ic_is_used = create_solver_model(candidate_ics, loads, battery, constraints, sanitized_ic_groups)
    
    solver = cp_model.CpSolver()
    solver.parameters.log_search_progress = True
    solver.parameters.max_time_in_seconds = 300.0 # 5ë¶„ íƒ€ì„ì•„ì›ƒ
    
    status = solver.Solve(model)

    if status not in (cp_model.OPTIMAL, cp_model.FEASIBLE):
        print("\nâŒ OR-Toolsê°€ ìœ íš¨í•œ ì†”ë£¨ì…˜ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.", file=sys.stderr)
        return

    print(f"\nğŸ‰ íƒìƒ‰ ì™„ë£Œ! (ìƒíƒœ: {solver.StatusName(status)})")
    
    # OR-Toolsê°€ ì°¾ì€ ìµœì í•´ (ì´ë¦„ ê¸°ë°˜)
    base_solution = {
        "cost": solver.ObjectiveValue() / 10000, # Cost (ì˜ˆ: 14.38)
        "active_edges": [(p, c) for (p, c), var in edges.items() if solver.Value(var)],
        # (ì‹œê°í™” í•¨ìˆ˜ê°€ 'used_ic_names'ë„ ì‚¬ìš©í•˜ë¯€ë¡œ ì¶”ê°€)
        "used_ic_names": {name for name, var in ic_is_used.items() if solver.Value(var)},
    }

    # --- ğŸ‘‡ [ì‹ ê·œ] 4. "ì •ë‹µì§€" ì‹œê°í™” (ìš”ì²­ ì‚¬í•­) ---
    print("\nğŸ–¼ï¸ 'ì •ë‹µì§€' ì†”ë£¨ì…˜ ì‹œê°í™” ìƒì„±...")
    
    # [ì‹ ê·œ] JSON íŒŒì¼ì´ ì €ì¥ë  'expert_data' í´ë” ê²½ë¡œë¥¼ ì¶”ì¶œ
    visualization_dir = os.path.dirname(output_filename)
    if not visualization_dir: # output_filenameì´ 'dataset.json'ì²˜ëŸ¼ ê²½ë¡œ ì—†ì´ íŒŒì¼ëª…ë§Œ ìˆì„ ê²½ìš°
        visualization_dir = "." # í˜„ì¬ í´ë”ì— ì €ì¥


    print_and_visualize_one_solution(
        base_solution, 
        candidate_ics, 
        loads, 
        battery, 
        constraints, 
        solution_index=0, # (ì •ë‹µì§€ëŠ” 0ë²ˆ ì¸ë±ìŠ¤ë¡œ ì €ì¥)
        custom_output_dir=visualization_dir
    )
    print(f"   - ì‹œê°í™” ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ. (ê²½ë¡œ: {visualization_dir})")
    # --- [ì‹ ê·œ] ì‹œê°í™” ì™„ë£Œ ---


    # --- 5. [í•µì‹¬] Transformerìš© "ì •ë‹µì§€" ë³€í™˜ ---
    print(f"\nğŸ’¾ 'ì •ë‹µì§€' ë°ì´í„° ìƒì„± ì‹œì‘ (Transformer ë§¤í•‘)...")
    
    # 5a. Transformerì˜ ë…¸ë“œ-ì¸ë±ìŠ¤ ë§¤í•‘ ë¡œë“œ
    print(f"   - Transformerì˜ ë…¸ë“œ-ì¸ë±ìŠ¤ ë§¤í•‘ ë¡œë“œ ì¤‘...")
    transformer_generator = PocatGenerator(config_file_path=config_filename)
    node_name_to_idx = {name: i for i, name in enumerate(transformer_generator.config.node_names)}
    
    # 5b. OR-Tools ì—£ì§€(ì´ë¦„) -> Transformer ì—£ì§€(ì¸ë±ìŠ¤) ë³€í™˜
    try:
        active_edges_indices = [
            (node_name_to_idx[p], node_name_to_idx[c]) 
            for p, c in base_solution['active_edges']
        ]
    except KeyError as e:
        print(f"âŒ ì´ë¦„-ì¸ë±ìŠ¤ ë§¤í•‘ ì‹¤íŒ¨: {e}.", file=sys.stderr)
        print("   OR-Toolsì™€ Transformerì˜ ë…¸ë“œ ì´ë¦„ì´ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.", file=sys.stderr)
        return

    # 5c. Transformerê°€ ì‚¬ìš©í•  ìµœì¢… ë³´ìƒ(Reward) ê³„ì‚°
    target_reward = base_solution['cost'] * -REWARD_WEIGHT_PATH

    # 5d. ì—£ì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ì—­ë°©í–¥ ë§µ(child -> parent)ìœ¼ë¡œ ë³€í™˜
    child_to_parent_map = {c_idx: p_idx for p_idx, c_idx in active_edges_indices}

    # 5e. Transformerì˜ ë¡œë“œ(Leaf) ë…¸ë“œ ì°¾ê¸°
    load_start_idx = 1 + transformer_generator.num_ics
    load_end_idx = load_start_idx + transformer_generator.num_loads
    load_indices = list(range(load_start_idx, load_end_idx))

    transformer_action_sequence = []
    
    # 5f. ê° ë¡œë“œë¶€í„° ë°°í„°ë¦¬ê¹Œì§€ ì—­ì¶”ì í•˜ì—¬ "ê²½ë¡œ" ìƒì„±
    for load_idx in load_indices:
        
        if load_idx not in child_to_parent_map:
            continue
            
        current_node_idx = load_idx
        path_actions = []
        
        path_actions.append(current_node_idx) 
        
        while current_node_idx in child_to_parent_map:
            parent_node_idx = child_to_parent_map[current_node_idx]
            path_actions.append(parent_node_idx)
            current_node_idx = parent_node_idx
            
            if current_node_idx == BATTERY_NODE_IDX: # 0 = BATTERY_NODE_IDX
                break
        
        transformer_action_sequence.append(path_actions)
        
    print(f"   - {len(load_indices)}ê°œ ë¡œë“œë¥¼ {len(transformer_action_sequence)}ê°œì˜ ì•¡ì…˜ ì‹œí€€ìŠ¤ë¡œ ë³€í™˜ ì™„ë£Œ.")

    expert_data_entry = {
        "config_file": config_filename,
        "cost": base_solution['cost'],
        "target_reward": target_reward,
        "action_sequences": transformer_action_sequence
    }

    # 5g. JSON íŒŒì¼ë¡œ ì €ì¥ (ë®ì–´ì“°ê¸° ëŒ€ì‹  'ì¶”ê°€' ë°©ì‹)
    output_dir = os.path.dirname(output_filename)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
    
    data_list = []
    if os.path.exists(output_filename):
        try:
            with open(output_filename, 'r', encoding='utf-8') as f:
                data_list = json.load(f)
            if not isinstance(data_list, list):
                data_list = []
        except json.JSONDecodeError:
            data_list = []
            
    data_list.append(expert_data_entry)
    
    with open(output_filename, 'w', encoding='utf-8') as f:
        json.dump(data_list, f, indent=2)
    
    print(f"âœ… 'ì •ë‹µì§€' 1ê°œë¥¼ {output_filename}ì— ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. (í˜„ì¬ íŒŒì¼ì— ì´ {len(data_list)}ê°œ)")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Pocat Expert Data Generator (OR-Tools to Transformer)")
    parser.add_argument(
        "--config_file", 
        type=str, 
        required=True, 
        help="Path to the configuration file (.json) to solve. (ì˜ˆ: configs/config_6.json)"
    )
    parser.add_argument(
        "--output_file", 
        type=str, 
        required=True, 
        help="Path to the output expert data JSON file (e.g., expert_data/dataset.json)."
    )
    parser.add_argument(
        "--max_sleep_current", 
        type=float, 
        default=None, 
        help="Override the max_sleep_current constraint (in Amperes)."
    )
    args = parser.parse_args()
    
    generate_expert_solution(args.config_file, args.output_file, args.max_sleep_current)